---
title: 'ALG Blog 2: How GenAI Works'
date: 2025-09-30
permalink: /posts/2025/09/ALG-blog-post-2/
tags:
  - AI
  - Education
  - Case Study
  - Ethics
---

The Cost of Generative AI

**News Article:**  
[How Generative AI Works and How It Fails](https://mit-serc.pubpub.org/pub/f3o5mpn6/release/1#learning)

## Purpose
  The purpose of this case study is to teach us how generative AI systems are trained, what data they depend on, and where they tend to fail. It also gives us the background needed to reflect on the ethics of AI development by emphasizing human labor and design choices that ultimately come with consequences.

## Summary
  The article explains how generative AI works by using machine learning to predict the “next word” until it can produce full responses, along with fine-tuning and human annotation to guide its behavior. It also highlights where these systems fall short, mentioning bias, hallucinations, and inaccurate outputs. Interestingly enough, it seems like AI models don’t truly understand anything, but simply imitate patterns from the data that they were trained on. With that being said, when that data is flawed or unfair, the model ends up repeating those flaws as well.

## Discussion (The use of creative work for training)
  1. **Is the practice of generative AI using the creative art of others ethical?**
  - I believe writers, artists, and other creators deserve recognition when their work is used to train AI. As someone who grew up doing arts and crafts, it feels personal to imagine my work being absorbed into a dataset without my permission. It feels wrong for AI to produce something “new” that actually comes from thousands of uncredited creators. At the very least, creators should be credited, and ideally, they should have a say in whether their work is used.

  2. **How can those who want to change the system go about doing so?**
  - Creating clear guidelines and push for new norms around responsible AI use is a step in that direction. For example, advocating for transparency, requiring companies to disclose training sources or even labeling AI-generated work. I have also heard about movements like the “NoAI” tags for artists, and platforms like DeviantArt and Adobe that have introduced opt-out tools. These efforts show that people are trying to change the norms around responsible AI use, even if the rules aren’t perfect yet.
  
  3. **Can the market solve the problem, such as through licensing agreements between publishers and AI companies?** 
  - Well, licensing agreements are starting to happen. Shutterstock licenses images for AI training, but also allows users to opt-out from their content being used for such training. However, AI is expanding so quickly that most content was already used before these agreements existed. Because of that, the market alone can’t solve everything, at least not yet. It’s like putting up a ‘no trespassing’ sign after everyone’s already walked through the yard.

  4. **What about copyright law — either interpreting existing law or by updating it? What other policy interventions might be helpful?**
  - Copyright law plays a huge role, but I don't think our current laws were made with AI training in mind. But,  broader policy ideas are being discussed, like requiring AI companies to give creators a legal right to opt in or out of training sets. Policies like these could help slow down the “wild west” feeling of current generative AI systems. It almost feels like we created a monster that we don't quite know how to train or handle yet.

## New Discussion Question
  **How does AI generated work affect how we value creativity and art?**

  As someone who has always been an artsy-craftsy kind of gal, I chose this question because I believe the younger generation won't value creativity and art anymore. Like making creative short stories for English class- they can just ask AI to do that. Or even just art class will be so different. We are losing originality, and it's horific.

## Reflection
  This case study resonated with me more than I expected. When AI art first started appearing, I honestly thought it was kind of silly. The results were terrible, and I never really stopped to think about what it might turn into. But after learning about how quickly it’s growing, learning, and spreading into our society, it doesn’t feel so silly anymore. Sure, it’s cool to see what AI can do, but I don’t think we really have the ability to control it yet. I can’t even imagine what it will look like in 10 years. What a time for it to be my turn to be an adult...