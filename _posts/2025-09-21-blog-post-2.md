---
title: 'Blog 2: Crafting Arguments'
date: 2025-09-21
permalink: /posts/2025/09/blog-post-2/
tags:
  - News Article
  - AI Videos
  - Social Media
  - Misinformation
---

AI Entertainment or Harm? How fake media is breaking our trust.

**News Article:**  
[How to spot an AI video? LOL, you can’t.’](https://www.washingtonpost.com/technology/2025/08/08/bunnies-trampoline-video-ai-fake-tiktok/)

## Article's Argument and Premise
  This Washington Post article examines how difficult it has become to recognize AI-generated videos, using a viral TikTok of bunnies on a trampoline as an example. I fully believed it was real... and so did millions of others. While harmless videos like this seem silly, the article argues that the inability to detect AI content weakens our trust in what we see online.

  From the article, we can premise that AI-generated videos are too realistic to circulate widely on platforms like TikTok.Many viewers cannot tell if something is AI or not, which is a problem when such videos are reaching millions of people with various levels of digital literacy. As AI content becomes harder to detect, the public is questioning their trust in online videos, thus rising the question of who bares the responsiblity for regulating such videos. 
  
  With these premises in mind, AI content on social media platforms, like TikTok, needs to be regulated as they promote misinformation and harms our trust in online content. Thus, platforms should be responsible for the consequences of causing such distrust and illusions, not users. Sure, some users are the ones creating the content and/or engage with the content, but only because the platform allows them to do so. You can't dress a baby in white and give them spaghetti and get mad at them for staining their shirt. The parent, aka the platform, is responsible here.

## Rebutting and the Fallacy
  Let's tackle these points from a different stance. While many people cannot reliably detect AI videos, some viewers can. Over time, our ability to detect AI videos will grow the more we use it. For example, my chronically online boyfriend can almost immediately tell when something is AI because he has seen tons of AI videos. Guarding ourselves from such content will only extend the problem further. We have to accept that AI is here to stay. We should try to work with it instead of working against it. Additionally, there's not much evidence we can use to show that AI videos are harming our trust in online content. The harm is subjective.
  
  Fallacy: However, the article’s main point, that being cautious of these AI videos, is unreasonable. Modern research shows that most Americans do not trust themselves to distinguish real vs. AI-generated content, which supports, not contradicts, the article’s concern.
  
  Rebuttal: Knowing that a video is AI does not inherently make it harmful. Many viewers actually find AI content amusing or creative. I sure thought the bunnies jumping on the trampoline video was entertaining. Additionally, clear labeling and increased digital literacy can mitigate trust issues without banning AI videos. Therefore, while AI videos can contribute to distrust, their presence alone does not necessarily harm public trust if platforms are transparent about it. Again, AI can be scary, especially since it's something new to us, but it doesn't have to mean harm. With the correct approach, we can minimize the negative consequences. The baby eating spaghetti will be just fine with a bib!

## Alternative Argument
  On the other hand, although AI bunny content may be harmless and entertaining, making AI content become the new norm is also normalizing the spread of misinformation. As of right now, AI content isn't regulated enough. Although most of the AI content I've seen has been silly, I have also seen it being involved in religion. One popular one being videos of Jesus circulating Facebook. I saw a TikTok video not too long ago of a middle aged woman crying because she saw an AI video of Jesus walking on water, believing it was real. Although the video was meant to be funny, many people don't recognize how powerful religion really is. It has caused mass hysteria in the past, even just recently with the belief of the rapture. People quit their jobs and sold their belongings. Imagine the chaos that would erupt if AI influenced religious beliefs.

## Recommendation
  I believe AI-generated videos should clearly state that they are AI-generated. Stuff like AI-generated bunnies should be allowed on platforms like TikTok because it isn't influencing any harm, but harmful videos, like deepfakes of politicians, should be flagged.

## Reflection
  As a college student living in the current digitalized world, AI videos/content has become something I'm sort of afraid of. Before, I will admit that I used to think it was funny when my mom would see a clearly fake video on Facebook and believe it to be real. However, I am now her. I frequently catch myself falling for AI-generated videos and pictures, and that terrifies me. AI content is just so new, and we are essentially the test dummies. I'm sure it will be heavily regulated in the future but right now, we are making the "rules" as the issues come. Overall a very interesting article, but it also made me slow down a little and think about how I interact with these fake videos. I know we shouldn't fight AI, but that doesn't mean I can't be afraid of it.