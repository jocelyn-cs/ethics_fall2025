---
title: 'Blog 2: Crafting Arguments'
date: 2025-09-21
permalink: /posts/2025/09/blog-post-2/
tags:
  - News Article
  - AI Videos
  - Social Media
  - Misinformation
---

AI Entertainment or Harm? How fake media is breaking our trust.

**News Article:**  
[How to spot an AI video? LOL, you can’t.’](https://www.washingtonpost.com/technology/2025/08/08/bunnies-trampoline-video-ai-fake-tiktok/)

## Article's Argument and Premise
  This Washington Post article examines how difficult it has become to recognize AI-generated videos, using a viral TikTok of bunnies on a trampoline as an example. I fully believed it was real... and so did millions of others. While harmless videos like this seem silly, the article argues that the inability to detect AI content weakens our trust in what we see online.

  - P1: AI-generated videos are too realistic and circulate widely on platforms like TikTok.
  - P2: Many viewers cannot tell if something is AI or not.
  - P3: As AI content becomes harder to detect, the public is questioning their trust in online videos
  - C: Therefore, allowing AI content on social media platforms like TikTok is needs to be regulated as it is promoting misinformation and harming our trust in online content.  

## Rebutting and the Fallacy
  - P2 challenge: While many people cannot reliably detect AI videos, some viewers can. Over time, our ability to detect AI videos will grow the more we use it. For example, my chronically online boyfriend can almost immediately tell when something is AI because he has seen tons of AI videos.
  - P3 challenge: There's not much evidence we can use to show that AI videos are harming our trust in online content. The harm is subjective.
  - Fallacy: Unlike my earlier claim, the article’s main point is not unreasonable. Modern research shows that most Americans do not trust themselves to distinguish real vs. AI-generated content, which supports, not contradicts, the article’s concern.
  
  - Rebuttal:
    - P4: Knowing that a video is AI does not inherently make it harmful. Many viewers actually find AI content amusing or creative. I sure thought the bunnies jumping on the trampoline was entertaining.
    - P5: Clear labeling and increased digital literacy can mitigate trust issues without banning AI videos.
    - R: Therefore, while AI videos can contribute to distrust, their presence alone does not necessarily harm public trust if platforms are transparent about it.

## Alternative Argument
  - C2: AI bunny content may be harmless and entertaining, but making AI content become the new norm is also normalizing the spread of misinformation.

## Recommendation
  I believe AI-generated videos should clearly state that they are AI-generated. Stuff like AI-generated bunnies should be allowed on platforms like TikTok because it isn't influencing any harm, but harmful videos, like deepfakes of politicians, should be flagged.

## Reflection
  As a college student living in the current digitalized world, AI videos/content has become something I'm sort of afraid of. Before, I will admit that I used to think it was funny when my mom would see a clearly fake video on Facebook and believe it to be real. However, I am now her. I frequently catch myself falling for AI-generated videos and pictures, and that terrifies me. AI content is just so new, and we are essentially the test dummies. I'm sure it will be heavily regulated in the future but right now, we are making the "rules" as the issues come. Overall a very interesting article, but it also made me slow down a little and think about how I interact with these fake videos. I know we shouldn't fight AI, but that doesn't mean I can't be afraid of it.